# -*- coding: utf-8 -*-
"""pcametric.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W7zZfrvIqZjKmhhB0-6JtL3rnhEIjpvu
"""

import numpy as np
import warnings
from typing import Tuple, List, Literal
from numpy import ndarray
from pandas import DataFrame
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# ---------------------------------------------------------
# Função auxiliar
# ---------------------------------------------------------
def _bound(value: float, range: Tuple[float, float]) -> float:
    low, high = range
    return max(low, min(high, value))

# ---------------------------------------------------------
# PCAMetric — Fiel ao artigo
# ---------------------------------------------------------
def PCAMetric(
    data_base: ndarray | DataFrame,
    data_comp: ndarray | DataFrame,
    num_components: int = None,
    normalization: Literal['precise', 'approx'] = 'precise',
    preprocess: Literal['std', 'mean'] = 'std'
):

    if num_components is None:
        num_components = data_base.shape[1]

    if data_base.shape[1] == 1:
        raise ValueError("Dataset com apenas 1 feature não pode ser usado.")

    if num_components > data_base.shape[1]:
        warnings.warn("num_components > d — ajustado automaticamente para d.", UserWarning)
        num_components = data_base.shape[1]

    # Normalização fiel ao artigo
    match normalization:
        case "precise":
            factor = data_base.shape[1] / (data_base.shape[1] + num_components - 2)
        case "approx":
            factor = 0.5
        case _:
            raise ValueError("normalization precisa ser 'precise' ou 'approx'.")

    # Pré-processamento
    match preprocess:
        case "std":
            b_scaled = StandardScaler().fit_transform(data_base)
            c_scaled = StandardScaler().fit_transform(data_comp)
        case "mean":
            b_scaled = data_base - np.mean(data_base, axis=0)
            c_scaled = data_comp - np.mean(data_comp, axis=0)
        case _:
            raise ValueError("preprocess precisa ser 'std' ou 'mean'.")

    # PCA independente
    b_pca = PCA(n_components=num_components)
    c_pca = PCA(n_components=num_components)

    b_proj = b_pca.fit_transform(b_scaled)
    c_proj = c_pca.fit_transform(c_scaled)

    # Diferença de variância explicada
    var_diff = factor * sum(
        abs(b_pca.explained_variance_ratio_ - c_pca.explained_variance_ratio_)
    )

    # Diferença angular da 1ª componente
    angle = min([
        np.arccos(_bound(b_pca.components_[0] @ (s * c_pca.components_[0]), (-1, 1)))
        for s in [1, -1]
    ])

    results = {
        "exp_var_diff": var_diff,
        "comp_angle_diff": (angle * 2) / np.pi
    }

    return results, b_proj, c_proj

# ---------------------------------------------------------
# AAD — Igual ao artigo
# ---------------------------------------------------------
def AAD(X: DataFrame, selected_features: List[int]) -> float:
    aad = 0
    not_selected = [i for i in range(X.shape[1]) if i not in selected_features]

    for p in not_selected:
        tmp = X.copy()
        tmp.iloc[:, p] = 0
        res, _, _ = PCAMetric(X, tmp)
        aad += res["comp_angle_diff"]

    if len(not_selected) > 0:
        aad /= len(not_selected)

    return aad