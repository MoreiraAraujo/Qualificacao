# -*- coding: utf-8 -*-
"""Kmedod.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1shLBnNZsUZ070Pvvp4N1dIpd6BrzDwX_
"""

!pip install -q pyclustering

from google.colab import drive
drive.mount('/content/drive')

"""Achar os k otimos"""

import numpy as np
import pandas as pd
import os

caminho_csv = "/content/drive/MyDrive/projeto1/resultados/matriz_distancias.csv"

matriz = pd.read_csv(caminho_csv, index_col=0)
dist_matrix = matriz.values

np.fill_diagonal(dist_matrix, 0)

print(f"Matriz carregada com dimens√£o: {dist_matrix.shape}")

RESULTADOS_PATH = "/content/drive/MyDrive/projeto1/resultados"
os.makedirs(RESULTADOS_PATH, exist_ok=True)

from pyclustering.cluster.kmedoids import kmedoids
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from scipy.spatial.distance import pdist

def dunn_index(data, labels):
    unique_clusters = np.unique(labels)
    min_inter = np.inf
    max_intra = 0
    for i in unique_clusters:
        cluster_i = data[labels == i]
        if cluster_i.shape[0] <= 1:
            continue
        dists = pdist(cluster_i)
        if len(dists) > 0:
            max_intra = max(max_intra, np.max(dists))
        for j in unique_clusters:
            if i >= j:
                continue
            cluster_j = data[labels == j]
            dist_ij = np.min(np.linalg.norm(cluster_i[:, None] - cluster_j[None, :], axis=2))
            if dist_ij < min_inter:
                min_inter = dist_ij
    return min_inter / max_intra if max_intra > 0 else 0

n = dist_matrix.shape[0]
results = []

for k in range(2, 11):
    print(f"Rodando K-Medoids para k={k} ...")
    initial_medoids = np.random.choice(n, k, replace=False).tolist()
    kmedoids_instance = kmedoids(dist_matrix, initial_medoids, data_type='distance_matrix')
    kmedoids_instance.process()
    clusters = kmedoids_instance.get_clusters()


    labels = np.zeros(n, dtype=int)
    for idx, cluster in enumerate(clusters):
        labels[cluster] = idx

    silhouette = silhouette_score(dist_matrix, labels, metric='precomputed')
    try:
        davies_bouldin = davies_bouldin_score(dist_matrix, labels)
    except:
        davies_bouldin = np.nan
    try:
        calinski_harabasz = calinski_harabasz_score(dist_matrix, labels)
    except:
        calinski_harabasz = np.nan
    dunn = dunn_index(dist_matrix, labels)

    custo_total = 0
    for medoid_idx, cluster in enumerate(clusters):
        medoid = cluster[0]  # pegando o primeiro do cluster como refer√™ncia
        custo_total += dist_matrix[np.ix_(cluster, [medoid])].sum()

    results.append({
        'k': k,
        'Custo_Total': custo_total,
        'Silhouette': silhouette,
        'DaviesBouldin': davies_bouldin,
        'Dunn': dunn,
        'CalinskiHarabasz': calinski_harabasz
    })

df_results = pd.DataFrame(results)
df_results.to_csv(os.path.join(RESULTADOS_PATH, "kmedoids_metricas.csv"), index=False)
print("\n‚úÖ M√©tricas salvas em CSV:")
print(df_results)

import pandas as pd
import matplotlib.pyplot as plt

caminho_csv = "/content/drive/MyDrive/projeto1/resultados/kmedoids_metricas.csv"
df = pd.read_csv(caminho_csv)

df_plot = df.copy()
df_plot['Custo_Total_norm'] = df_plot['Custo_Total'] / df_plot['Custo_Total'].max()
df_plot['DaviesBouldin_norm'] = 1 - (df_plot['DaviesBouldin'] / df_plot['DaviesBouldin'].max())
df_plot['CalinskiHarabasz_norm'] = df_plot['CalinskiHarabasz'] / df_plot['CalinskiHarabasz'].max()
df_plot['Dunn_norm'] = df_plot['Dunn'] / df_plot['Dunn'].max()
df_plot['Silhouette_norm'] = df_plot['Silhouette'] / df_plot['Silhouette'].max()

plt.figure(figsize=(12, 7))
plt.plot(df_plot['k'], df_plot['Custo_Total_norm'], marker='o', label='Custo Total (normalizado)')
plt.plot(df_plot['k'], df_plot['Silhouette_norm'], marker='o', label='Silhouette (normalizado)')
plt.plot(df_plot['k'], df_plot['DaviesBouldin_norm'], marker='o', label='Davies-Bouldin (invertido)')
plt.plot(df_plot['k'], df_plot['Dunn_norm'], marker='o', label='Dunn (normalizado)')
plt.plot(df_plot['k'], df_plot['CalinskiHarabasz_norm'], marker='o', label='Calinski-Harabasz (normalizado)')

k_otimo = df_plot.loc[df_plot['Silhouette'].idxmax(), 'k']
plt.axvline(x=k_otimo, color='red', linestyle='--', label=f'k √≥timo ‚âà {k_otimo}')

plt.xlabel("N√∫mero de clusters (k)")
plt.ylabel("M√©tricas normalizadas")
plt.title("Avalia√ß√£o de K-Medoids para diferentes k (curva do cotovelo e m√©tricas)")
plt.grid(True)
plt.legend()
plt.show()

"""Kmedoid"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.manifold import MDS
from pyclustering.cluster.kmedoids import kmedoids
from scipy.spatial.distance import squareform


caminho_csv = "/content/drive/MyDrive/projeto1/resultados/matriz_distancias.csv"
matriz = pd.read_csv(caminho_csv, index_col=0)
dist_matrix = matriz.values
np.fill_diagonal(dist_matrix, 0)

n = dist_matrix.shape[0]
k = 2

initial_medoids = np.random.choice(n, k, replace=False).tolist()
kmedoids_instance = kmedoids(dist_matrix, initial_medoids, data_type='distance_matrix')
kmedoids_instance.process()
clusters = kmedoids_instance.get_clusters()
labels = np.zeros(n, dtype=int)
for idx, cluster in enumerate(clusters):
    labels[cluster] = idx


for i in range(k):
    print(f"Cluster {i+1}: {len(clusters[i])} datasets")


mds2d = MDS(n_components=2, dissimilarity='precomputed', random_state=42)
coords2d = mds2d.fit_transform(dist_matrix)

mds3d = MDS(n_components=3, dissimilarity='precomputed', random_state=42)
coords3d = mds3d.fit_transform(dist_matrix)


colors = ['red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'brown', 'pink']

plt.figure(figsize=(10,8))
for i in range(k):
    plt.scatter(coords2d[labels==i, 0], coords2d[labels==i, 1], color=colors[i], s=100, label=f'Cluster {i+1}')
    for idx in np.where(labels==i)[0]:
        plt.text(coords2d[idx,0], coords2d[idx,1], matriz.index[idx], fontsize=8)
plt.title("K-Medoids Clusters (2D) - k=2")
plt.xlabel("Componente 1")
plt.ylabel("Componente 2")
plt.legend()
plt.grid(True)
plt.show()


from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(figsize=(12,10))
ax = fig.add_subplot(111, projection='3d')
for i in range(k):
    ax.scatter(coords3d[labels==i, 0], coords3d[labels==i, 1], coords3d[labels==i, 2],
               color=colors[i], s=100, label=f'Cluster {i+1}')
    for idx in np.where(labels==i)[0]:
        ax.text(coords3d[idx,0], coords3d[idx,1], coords3d[idx,2], matriz.index[idx], fontsize=8)
ax.set_title("K-Medoids Clusters (3D) - k=2")
ax.set_xlabel("Componente 1")
ax.set_ylabel("Componente 2")
ax.set_zlabel("Componente 3")
ax.legend()
plt.show()



df_clusters = pd.DataFrame({
    'Dataset': matriz.index,
    'Cluster': labels + 1  # +1 para ficar Cluster 1, Cluster 2...
})

caminho_saida = "/content/drive/MyDrive/projeto1/resultados/kmedoids_clusters_k2.csv"
df_clusters.to_csv(caminho_saida, index=False)

print(f"Resultados dos clusters salvos em: {caminho_saida}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.manifold import MDS
from pyclustering.cluster.kmedoids import kmedoids
from scipy.spatial.distance import squareform

caminho_csv = "/content/drive/MyDrive/projeto1/resultados/matriz_distancias.csv"
matriz = pd.read_csv(caminho_csv, index_col=0)
dist_matrix = matriz.values
np.fill_diagonal(dist_matrix, 0)
n = dist_matrix.shape[0]
k = 3

initial_medoids = np.random.choice(n, k, replace=False).tolist()
kmedoids_instance = kmedoids(dist_matrix, initial_medoids, data_type='distance_matrix')
kmedoids_instance.process()
clusters = kmedoids_instance.get_clusters()
labels = np.zeros(n, dtype=int)
for idx, cluster in enumerate(clusters):
    labels[cluster] = idx


for i in range(k):
    print(f"Cluster {i+1}: {len(clusters[i])} datasets")


mds2d = MDS(n_components=2, dissimilarity='precomputed', random_state=42)
coords2d = mds2d.fit_transform(dist_matrix)

mds3d = MDS(n_components=3, dissimilarity='precomputed', random_state=42)
coords3d = mds3d.fit_transform(dist_matrix)


colors = ['red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'brown', 'pink']

plt.figure(figsize=(10,8))
for i in range(k):
    plt.scatter(coords2d[labels==i, 0], coords2d[labels==i, 1], color=colors[i], s=100, label=f'Cluster {i+1}')
    for idx in np.where(labels==i)[0]:
        plt.text(coords2d[idx,0], coords2d[idx,1], matriz.index[idx], fontsize=8)
plt.title("K-Medoids Clusters (2D) - k=2")
plt.xlabel("Componente 1")
plt.ylabel("Componente 2")
plt.legend()
plt.grid(True)
plt.show()


from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(figsize=(12,10))
ax = fig.add_subplot(111, projection='3d')
for i in range(k):
    ax.scatter(coords3d[labels==i, 0], coords3d[labels==i, 1], coords3d[labels==i, 2],
               color=colors[i], s=100, label=f'Cluster {i+1}')
    for idx in np.where(labels==i)[0]:
        ax.text(coords3d[idx,0], coords3d[idx,1], coords3d[idx,2], matriz.index[idx], fontsize=8)
ax.set_title("K-Medoids Clusters (3D) - k=2")
ax.set_xlabel("Componente 1")
ax.set_ylabel("Componente 2")
ax.set_zlabel("Componente 3")
ax.legend()
plt.show()


df_clusters = pd.DataFrame({
    'Dataset': matriz.index,
    'Cluster': labels + 1  # +1 para ficar Cluster 1, Cluster 2...
})

caminho_saida = "/content/drive/MyDrive/projeto1/resultados/kmedoids_clusters_k3.csv"
df_clusters.to_csv(caminho_saida, index=False)

print(f"Resultados dos clusters salvos em: {caminho_saida}")

"""HDBSCAN"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import hdbscan
from sklearn.decomposition import PCA


caminho_csv = "/content/drive/MyDrive/projeto1/resultados/matriz_distancias.csv"
dist_matrix = pd.read_csv(caminho_csv, index_col=0).values
dataset_names = pd.read_csv(caminho_csv, index_col=0).index


clusterer = hdbscan.HDBSCAN(
    min_cluster_size=10,
    min_samples=5,
    metric='precomputed'
)
labels = clusterer.fit_predict(dist_matrix)

df_clusters = pd.DataFrame({
    'Dataset': dataset_names,
    'Cluster': labels
})

df_clusters['Cluster_size'] = df_clusters.groupby('Cluster')['Cluster'].transform('count')
df_clusters.sort_values(['Cluster', 'Dataset'], inplace=True)
df_clusters.to_csv("/content/drive/MyDrive/projeto1/resultados/hdbscan_clusters.csv", index=False)


pca = PCA(n_components=3)
coords = pca.fit_transform(dist_matrix)


plt.figure(figsize=(10,8))
unique_labels = np.unique(labels)
colors = plt.cm.get_cmap('tab20', len(unique_labels))

for i, cluster in enumerate(unique_labels):
    cluster_points = coords[labels == cluster]
    plt.scatter(cluster_points[:,0], cluster_points[:,1],
                s=50, color=colors(i), label=f"Cluster {cluster}" if cluster != -1 else "Ru√≠do")

    for idx, name in zip(np.where(labels==cluster)[0], dataset_names[labels==cluster]):
        if cluster != -1:
            plt.text(coords[idx,0], coords[idx,1], name, fontsize=8)

plt.title("HDBSCAN - Clusters 2D")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.legend()
plt.grid(True)
plt.show()


fig = plt.figure(figsize=(12,10))
ax = fig.add_subplot(111, projection='3d')

for i, cluster in enumerate(unique_labels):
    cluster_points = coords[labels == cluster]
    ax.scatter(cluster_points[:,0], cluster_points[:,1], cluster_points[:,2],
               s=50, color=colors(i), label=f"Cluster {cluster}" if cluster != -1 else "Ru√≠do")
    for idx, name in zip(np.where(labels==cluster)[0], dataset_names[labels==cluster]):
        if cluster != -1:
            ax.text(coords[idx,0], coords[idx,1], coords[idx,2], name, fontsize=8)

ax.set_title("HDBSCAN - Clusters 3D")
ax.set_xlabel("PC1")
ax.set_ylabel("PC2")
ax.set_zlabel("PC3")
ax.legend()
plt.show()


print("Resumo de clusters HDBSCAN:")
print(df_clusters.groupby('Cluster').size())

"""Represetantes"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.decomposition import PCA


clusters_path = "/content/drive/MyDrive/projeto1/resultados/kmedoids_clusters_k3.csv"
df_clusters = pd.read_csv(clusters_path, index_col=0)  # coluna 0 = nome do dataset
dataset_names = df_clusters.index.tolist()
labels = df_clusters['Cluster'].values  # coluna 'Cluster' cont√©m os n√∫meros do cluster


representantes = []

for cluster_id in np.unique(labels):
    indices_cluster = np.where(labels == cluster_id)[0]
    cluster_vectors = np.array([dist_matrix[i] for i in indices_cluster])
    mean_vector = cluster_vectors.mean(axis=0)
    dist_to_mean = np.linalg.norm(cluster_vectors - mean_vector, axis=1)
    medoid_idx = indices_cluster[np.argmin(dist_to_mean)]
    medoid_name = dataset_names[medoid_idx]

    representantes.append({
        "Cluster": cluster_id,
        "Medoid_Index": medoid_idx,
        "Dataset_Name": medoid_name
    })

# -------------------------------
# Salvar representantes em CSV
# -------------------------------
df_representantes = pd.DataFrame(representantes)
csv_path = "/content/drive/MyDrive/projeto1/resultados/medoids_representantes_k3.csv"
df_representantes.to_csv(csv_path, index=False)
print(f"‚úÖ Representantes salvos em: {csv_path}")

# -------------------------------
# PCA 2D
# -------------------------------
pca_2D = PCA(n_components=2)
X_2D = pca_2D.fit_transform(dist_matrix)

plt.figure(figsize=(10, 8))
colors = ['r', 'g', 'b', 'c', 'm', 'y']

for cluster_id in np.unique(labels):
    indices_cluster = np.where(labels == cluster_id)[0]
    plt.scatter(X_2D[indices_cluster, 0], X_2D[indices_cluster, 1],
                label=f"Cluster {cluster_id+1}", alpha=0.6)

# Destacar representantes
for rep in representantes:
    idx = rep["Medoid_Index"]
    plt.scatter(X_2D[idx, 0], X_2D[idx, 1], color='k', s=150, marker='X')
    plt.text(X_2D[idx, 0]+0.02, X_2D[idx, 1]+0.02, rep["Dataset_Name"], fontsize=9)

plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.title("Representantes dos Clusters (K-Medoids, k=3) - 2D")
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------
# PCA 3D
# -------------------------------
pca_3D = PCA(n_components=3)
X_3D = pca_3D.fit_transform(dist_matrix)

fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(111, projection='3d')

for cluster_id in np.unique(labels):
    indices_cluster = np.where(labels == cluster_id)[0]
    ax.scatter(X_3D[indices_cluster, 0], X_3D[indices_cluster, 1], X_3D[indices_cluster, 2],
               color=colors[cluster_id % len(colors)], label=f"Cluster {cluster_id+1}", alpha=0.6)

# Destacar representantes
for rep in representantes:
    idx = rep["Medoid_Index"]
    ax.scatter(X_3D[idx, 0], X_3D[idx, 1], X_3D[idx, 2], color='k', s=150, marker='X')
    ax.text(X_3D[idx, 0]+0.02, X_3D[idx, 1]+0.02, X_3D[idx, 2]+0.02, rep["Dataset_Name"], fontsize=9)

ax.set_xlabel("PCA 1")
ax.set_ylabel("PCA 2")
ax.set_zlabel("PCA 3")
ax.set_title("Representantes dos Clusters (K-Medoids, k=3) - 3D")
ax.legend()
plt.show()

!pip install deap

"""Otimiza√ß√£o dos Hiperpar√¢metros do SVM com NSGA-II"""

import pandas as pd
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score
from deap import base, creator, tools, algorithms
import random
import warnings

warnings.filterwarnings("ignore")


rep_path = "/content/drive/MyDrive/projeto1/resultados/medoids_representantes_k3.csv"
df_rep = pd.read_csv(rep_path)
dataset_names = df_rep['Dataset_Name'].tolist()


# Espa√ßo de hiperpar√¢metros SVM em log2
log2_C_range = (-15, 15)
log2_gamma_range = (-15, 15)


# Fun√ß√£o de avalia√ß√£o NSGA-II (Classifica√ß√£o)
def evaluate(params, X, y):

    log2_C, log2_gamma = params
    C = 2 ** log2_C
    gamma = 2 ** log2_gamma

    model = SVC(kernel='rbf', C=C, gamma=gamma)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    acc_scores, bac_scores, f1_scores = [], [], []

    for train_idx, test_idx in kf.split(X):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        acc_scores.append(accuracy_score(y_test, y_pred))
        bac_scores.append(balanced_accuracy_score(y_test, y_pred))
        f1_scores.append(f1_score(y_test, y_pred, zero_division=0))


    return -np.mean(acc_scores), -np.mean(bac_scores), -np.mean(f1_scores)


# Configura√ß√£o DEAP
creator.create("FitnessMulti", base.Fitness, weights=(-1.0, -1.0, -1.0))
creator.create("Individual", list, fitness=creator.FitnessMulti)

toolbox = base.Toolbox()
toolbox.register("attr_float", random.uniform, -15, 15)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=2)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=3, indpb=0.3)
toolbox.register("select", tools.selNSGA2)


results = []

for dataset_name in dataset_names:

    print(f"\nüîµ Rodando NSGA-II para dataset: {dataset_name}")


    df = pd.read_csv(f"/content/drive/MyDrive/projeto1/datasets/{dataset_name}.csv")


    target_col = df.columns[-1]
    X = df.drop(columns=[target_col]).values
    y = df[target_col].values


    toolbox.register("evaluate", evaluate, X=X, y=y)


    pop = toolbox.population(n=20)

    # Executar NSGA-II
    algorithms.eaMuPlusLambda(
        pop, toolbox,
        mu=20, lambda_=40,
        cxpb=0.6, mutpb=0.3,
        ngen=10, verbose=False
    )

    best_ind = tools.selBest(pop, 1)[0]
    C_best = 2 ** best_ind[0]
    gamma_best = 2 ** best_ind[1]
    metrics_best = evaluate(best_ind, X, y)

    print(f"‚û° Melhor indiv√≠duo:")
    print(f"   C = {C_best:.6f}")
    print(f"   gamma = {gamma_best:.6f}")
    print(f"   Accuracy = {-metrics_best[0]:.4f}")
    print(f"   BAC = {-metrics_best[1]:.4f}")
    print(f"   F1 = {-metrics_best[2]:.4f}")

    results.append({
        "Dataset": dataset_name,
        "Best_C": C_best,
        "Best_Gamma": gamma_best,
        "Accuracy": -metrics_best[0],
        "Balanced_Accuracy": -metrics_best[1],
        "F1_score": -metrics_best[2]
    })


df_results = pd.DataFrame(results)
df_results.to_csv("/content/drive/MyDrive/projeto1/resultados/best_svm_params_classification.csv", index=False)

print("\n‚úÖ Finalizado! Par√¢metros √≥timos salvos com sucesso!")

"""OS datasets no plano"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


df = pd.read_csv("/content/drive/MyDrive/projeto1/resultados/best_svm_params_classification.csv")


df["log2_C"] = np.log2(df["Best_C"])
df["log2_gamma"] = np.log2(df["Best_Gamma"])


plt.figure(figsize=(8,6))
plt.scatter(df["log2_C"], df["log2_gamma"], s=200)


for i, row in df.iterrows():
    plt.text(row["log2_C"] + 0.2, row["log2_gamma"] + 0.2, row["Dataset"], fontsize=12)

plt.xlabel("log‚ÇÇ(C)", fontsize=14)
plt.ylabel("log‚ÇÇ(gamma)", fontsize=14)
plt.title("Posi√ß√£o dos Datasets no Espa√ßo de Hiperpar√¢metros do SVM (NSGA-II)", fontsize=15)
plt.grid(True)
plt.show()

""" MAtriz de dist√¢ncias"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv("/content/drive/MyDrive/projeto1/resultados/best_svm_params_classification.csv")


# Transformar em escala log2 para C e gamma
df["log2_C"] = np.log2(df["Best_C"])
df["log2_gamma"] = np.log2(df["Best_Gamma"])


# Codificar kernel (RBF = 1)
df["kernel_code"] = 1  # s√≥ RBF aqui, se houver outros, colocar c√≥digos diferentes


vectors = df[["log2_C", "log2_gamma", "kernel_code"]].values


def custom_distance(v1, v2, w_C=1.0, w_gamma=1.0, w_kernel=1.0):
    d_C = w_C * abs(v1[0] - v2[0])
    d_gamma = w_gamma * abs(v1[1] - v2[1])
    d_kernel = w_kernel * abs(v1[2] - v2[2])
    return d_C + d_gamma + d_kernel


n = len(vectors)
dist_matrix = np.zeros((n, n))

for i in range(n):
    for j in range(n):
        dist_matrix[i, j] = custom_distance(vectors[i], vectors[j])


dist_df = pd.DataFrame(dist_matrix, index=df["Dataset"], columns=df["Dataset"])

plt.figure(figsize=(8,6))
sns.heatmap(dist_df, annot=True, cmap="viridis")
plt.title("Matriz de Dist√¢ncias entre Datasets (C, gamma, kernel)")
plt.show()